{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0c8745c6-6b32-4d96-bef3-6f6bebd3f99a",
   "metadata": {},
   "source": [
    "Query:\n",
    "```SQL\n",
    "DELETE FROM DESASTRES_BDE.dbo.DESASTRES_FINAL;\n",
    "INSERT INTO DESASTRES_BDE.dbo.DESASTRES_FINAL\n",
    "SELECT x.Cuatrenio, AVG(x.Temperatura) AS Temp_AVG, AVG(x.NivelOxigeno) AS Oxi_AVG,\n",
    "SUM(x.Tsunamis) AS T_Tsunamis,SUM(x.OlasCalor) AS T_OlasCalor,SUM(x.Terremotos) AS T_Terremotos,\n",
    "SUM(x.Erupciones) AS T_Erupciones,SUM(x.Incendios) AS T_Incendios,\n",
    "AVG(x.Muertes_Jovenes) as M_Jovenes_AVG,AVG(x.Muertes_Adultos) as M_Adultos_AVG, AVG(x.Muertes_Ancianos) as M_Ancianos_AVG\n",
    "FROM\n",
    "(SELECT CASE WHEN c.anio < 2026 THEN '2023-2026' ELSE '2027-2030' END AS Cuatrenio,\n",
    "Temperatura =c.temperatura,\n",
    "NivelOxigeno =c.oxigeno,\n",
    "Tsunamis= d.Tsunamis,\n",
    "OlasCalor= d.Olas_calor,\n",
    "Terremotos= d.Terremotos,\n",
    "Erupciones= d.Erupciones,\n",
    "Incendios=d.Incendios, \n",
    "Muertes_Jovenes= m.R_Menor15 + m.R_15_a_30,\n",
    "Muertes_Adultos= m.R_30_a_45 +m.R_45_a_60,\n",
    "Muertes_Ancianos= m.R_M_a_60\n",
    "FROM DESASTRES.dbo.clima as c\n",
    "JOIN DESASTRES.dbo.desastres as d ON c.anio =d.anio\n",
    "JOIN DESASTRES.dbo.muertes as m ON c.anio = m.anio) x\n",
    "GROUP BY x.Cuatrenio;\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8881c9f6-ab17-4ec3-ad6b-88ac57ba2ebf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "driver_path = \"/home/coder/working_dir/driver_jdbc/postgresql-42.2.27.jre7.jar\"\n",
    "\n",
    "os.environ['PYSPARK_SUBMIT_ARGS'] = f'--driver-class-path {driver_path} --jars {driver_path} pyspark-shell'\n",
    "os.environ['SPARK_CLASSPATH'] = driver_path\n",
    "\n",
    "# Create SparkSession \n",
    "spark = SparkSession.builder \\\n",
    "        .master(\"local\") \\\n",
    "        .appName(\"Conexion entre Pyspark y Postgres\") \\\n",
    "        .config(\"spark.jars\", driver_path) \\\n",
    "        .config(\"spark.executor.extraClassPath\", driver_path) \\\n",
    "        .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "770adb0a-7caa-4dc8-a0f9-44ffc081f3cc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Postgres connection settings\n",
    "pg_url = \"jdbc:postgresql://171.1.1.2:5435/\"\n",
    "pg_user = \"postgres\" # not recommended to have this value in the code\n",
    "pg_password = \"postgres\" # not recommended to have this value in the code\n",
    "pg_driver = \"org.postgresql.Driver\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a5a12f26-af29-41a3-a34d-36c4384c5cd0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- anio: integer (nullable = true)\n",
      " |-- temperatura: double (nullable = true)\n",
      " |-- oxigeno: double (nullable = true)\n",
      "\n",
      "+----+-----------+-------+\n",
      "|anio|temperatura|oxigeno|\n",
      "+----+-----------+-------+\n",
      "|2023|       22.5|  230.0|\n",
      "|2024|       22.7|  228.6|\n",
      "|2025|       22.9|  227.5|\n",
      "|2026|       23.1|  226.7|\n",
      "|2027|       23.2|  226.4|\n",
      "|2028|       23.4|  226.2|\n",
      "|2029|       23.6|  226.1|\n",
      "|2030|       23.8|  225.1|\n",
      "+----+-----------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create the connection and read the table\n",
    "df_clima = spark.read \\\n",
    "    .format(\"jdbc\") \\\n",
    "    .option(\"url\", pg_url+\"desastres\") \\\n",
    "    .option(\"dbtable\", \"clima\") \\\n",
    "    .option(\"user\", pg_user) \\\n",
    "    .option(\"password\", pg_password) \\\n",
    "    .option(\"driver\", pg_driver) \\\n",
    "    .load()\n",
    "\n",
    "df_clima.printSchema()\n",
    "df_clima.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3ff74db4-3561-4cd2-825b-83be2294bce0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- anio: integer (nullable = true)\n",
      " |-- tsunamis: integer (nullable = true)\n",
      " |-- olas_calor: integer (nullable = true)\n",
      " |-- terremotos: integer (nullable = true)\n",
      " |-- erupciones: integer (nullable = true)\n",
      " |-- incendios: integer (nullable = true)\n",
      "\n",
      "+----+--------+----------+----------+----------+---------+\n",
      "|anio|tsunamis|olas_calor|terremotos|erupciones|incendios|\n",
      "+----+--------+----------+----------+----------+---------+\n",
      "|2023|       2|        15|         6|         7|       50|\n",
      "|2024|       1|        12|         8|         9|       46|\n",
      "|2025|       3|        16|         5|         6|       47|\n",
      "|2026|       4|        12|        10|        13|       52|\n",
      "|2027|       5|        12|         6|         5|       41|\n",
      "|2028|       4|        18|         3|         2|       39|\n",
      "|2029|       2|        19|         5|         6|       49|\n",
      "|2030|       4|        20|         6|         7|       50|\n",
      "+----+--------+----------+----------+----------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create the connection and read the table\n",
    "df_desastres = spark.read \\\n",
    "    .format(\"jdbc\") \\\n",
    "    .option(\"url\", pg_url+\"desastres\") \\\n",
    "    .option(\"dbtable\", \"desastres\") \\\n",
    "    .option(\"user\", pg_user) \\\n",
    "    .option(\"password\", pg_password) \\\n",
    "    .option(\"driver\", pg_driver) \\\n",
    "    .load()\n",
    "\n",
    "df_desastres.printSchema()\n",
    "df_desastres.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a6923b6e-744b-4a70-9e00-7e852e8e55d1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- anio: integer (nullable = true)\n",
      " |-- r_menor15: integer (nullable = true)\n",
      " |-- r_15_a_30: integer (nullable = true)\n",
      " |-- r_30_a_45: integer (nullable = true)\n",
      " |-- r_45_a_60: integer (nullable = true)\n",
      " |-- r_m_a_60: integer (nullable = true)\n",
      "\n",
      "+----+---------+---------+---------+---------+--------+\n",
      "|anio|r_menor15|r_15_a_30|r_30_a_45|r_45_a_60|r_m_a_60|\n",
      "+----+---------+---------+---------+---------+--------+\n",
      "|2023|     1000|     1300|     1200|     1150|    1500|\n",
      "|2024|     1200|     1250|     1260|     1678|    1940|\n",
      "|2025|      987|     1130|     1160|     1245|    1200|\n",
      "|2026|     1560|     1578|     1856|     1988|    1245|\n",
      "|2027|     1002|      943|     1345|     1232|     986|\n",
      "|2028|      957|      987|     1856|     1567|    1756|\n",
      "|2029|     1285|     1376|     1465|     1432|    1236|\n",
      "|2030|     1145|     1456|     1345|     1654|    1877|\n",
      "+----+---------+---------+---------+---------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create the connection and read the table\n",
    "df_muertes = spark.read \\\n",
    "    .format(\"jdbc\") \\\n",
    "    .option(\"url\", pg_url+\"desastres\") \\\n",
    "    .option(\"dbtable\", \"muertes\") \\\n",
    "    .option(\"user\", pg_user) \\\n",
    "    .option(\"password\", pg_password) \\\n",
    "    .option(\"driver\", pg_driver) \\\n",
    "    .load()\n",
    "\n",
    "df_muertes.printSchema()\n",
    "df_muertes.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c88fbd26-1505-4fb4-a23f-a03da21307ad",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create temporary tables\n",
    "df_clima.createOrReplaceTempView(\"clima\")          # clima\n",
    "df_desastres.createOrReplaceTempView(\"desastres\")  # desastres\n",
    "df_muertes.createOrReplaceTempView(\"muertes\")      # muertes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0db8427d-364d-4fd2-acbb-b70f5df18b3f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Cuatrenio: string (nullable = false)\n",
      " |-- Temp_AVG: double (nullable = true)\n",
      " |-- Oxi_AVG: double (nullable = true)\n",
      " |-- T_Tsunamis: long (nullable = true)\n",
      " |-- T_OlasCalor: long (nullable = true)\n",
      " |-- T_Terremotos: long (nullable = true)\n",
      " |-- T_Erupciones: long (nullable = true)\n",
      " |-- T_Incendios: long (nullable = true)\n",
      " |-- M_Jovenes_AVG: double (nullable = true)\n",
      " |-- M_Adultos_AVG: double (nullable = true)\n",
      " |-- M_Ancianos_AVG: double (nullable = true)\n",
      "\n",
      "+---------+------------------+------------------+----------+-----------+------------+------------+-----------+-------------+------------------+------------------+\n",
      "|Cuatrenio|          Temp_AVG|           Oxi_AVG|T_Tsunamis|T_OlasCalor|T_Terremotos|T_Erupciones|T_Incendios|M_Jovenes_AVG|     M_Adultos_AVG|    M_Ancianos_AVG|\n",
      "+---------+------------------+------------------+----------+-----------+------------+------------+-----------+-------------+------------------+------------------+\n",
      "|2027-2030|23.419999999999998|             226.1|        19|         81|          30|          33|        231|       2457.8|            3148.0|            1420.0|\n",
      "|2023-2026|              22.7|228.70000000000002|         6|         43|          19|          22|        143|       2289.0|2564.3333333333335|1546.6666666666667|\n",
      "+---------+------------------+------------------+----------+-----------+------------+------------+-----------+-------------+------------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_desastres_final = spark.sql(\"\"\"\n",
    "SELECT \n",
    "  x.Cuatrenio, \n",
    "  AVG(x.Temperatura) AS Temp_AVG, \n",
    "  AVG(x.NivelOxigeno) AS Oxi_AVG, \n",
    "  SUM(x.Tsunamis) AS T_Tsunamis, \n",
    "  SUM(x.OlasCalor) AS T_OlasCalor, \n",
    "  SUM(x.Terremotos) AS T_Terremotos, \n",
    "  SUM(x.Erupciones) AS T_Erupciones, \n",
    "  SUM(x.Incendios) AS T_Incendios, \n",
    "  AVG(x.Muertes_Jovenes) as M_Jovenes_AVG, \n",
    "  AVG(x.Muertes_Adultos) as M_Adultos_AVG, \n",
    "  AVG(x.Muertes_Ancianos) as M_Ancianos_AVG \n",
    "FROM \n",
    "  (\n",
    "    SELECT \n",
    "      CASE WHEN c.anio < 2026 THEN '2023-2026' ELSE '2027-2030' END AS Cuatrenio, \n",
    "      c.temperatura as Temperatura, \n",
    "      c.oxigeno as NivelOxigeno, \n",
    "      d.Tsunamis as Tsunamis, \n",
    "      d.Olas_calor as OlasCalor, \n",
    "      d.Terremotos as Terremotos, \n",
    "      d.Erupciones as Erupciones, \n",
    "      d.Incendios as Incendios, \n",
    "      (m.R_Menor15 + m.R_15_a_30) as Muertes_Jovenes, \n",
    "      (m.R_30_a_45 + m.R_45_a_60) as Muertes_Adultos, \n",
    "      m.R_M_a_60 as Muertes_Ancianos\n",
    "    FROM \n",
    "      clima as c \n",
    "      JOIN desastres as d ON c.anio = d.anio \n",
    "      JOIN muertes as m ON c.anio = m.anio\n",
    "  ) x \n",
    "GROUP BY \n",
    "  x.Cuatrenio;\n",
    "\"\"\")\n",
    "\n",
    "df_desastres_final.printSchema()\n",
    "df_desastres_final.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e065ac99-5ca7-40ef-b669-a517b4a5af6c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_desastres_final.write \\\n",
    "    .mode('overwrite') \\\n",
    "    .format(\"jdbc\") \\\n",
    "    .option(\"url\", pg_url+\"desastres_bde\") \\\n",
    "    .option(\"dbtable\", \"desastres_final\") \\\n",
    "    .option(\"user\", pg_user) \\\n",
    "    .option(\"password\", pg_password) \\\n",
    "    .option(\"driver\", pg_driver) \\\n",
    "    .save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06536b68-608e-4d39-9c66-e8e809547204",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
